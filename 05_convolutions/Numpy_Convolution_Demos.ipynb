{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 신경망 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the batch, multi-channel convolution operation implemented in Numpy (that you can find [here](../lincoln/lincoln/conv.py)) to train a small convolutional neural network to more than 90% accuracy on MNIST.\n",
    "\n",
    "이 노트북은 넘파이에 구현된 배치 학습 및 다채널 합성곱 연산을 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# 예제 파일 경로로 수정한 다음 주석 해제\n",
    "# sys.path.append(r'/to/your/example_code/path/lincoln')\n",
    "sys.path.append(r'/home/flourscent/DLFS_code/lincoln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lincoln\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import SoftmaxCrossEntropy, MeanSquaredError\n",
    "from lincoln.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from lincoln.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from lincoln.network import NeuralNetwork\n",
    "from lincoln.train import Trainer\n",
    "from lincoln.utils import mnist\n",
    "from lincoln.layers import Conv2D\n",
    "\n",
    "#mnist.init() # 최초 실행시 주석 해제, 이후 다시 주석 처리할 것\n",
    "\n",
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)\n",
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv, X_test_conv = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''검증 데이터에 대한 모델의 정확도 : \n",
    "    {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 밑바닥부터 구현한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 학습 후 손실값은  31.191501893742316\n",
      "10 배치 학습 후 손실값은  14.15039049044619\n",
      "20 배치 학습 후 손실값은  8.507022939163363\n",
      "30 배치 학습 후 손실값은  9.816083122397819\n",
      "40 배치 학습 후 손실값은  2.707136219766947\n",
      "50 배치 학습 후 손실값은  5.039261518632477\n",
      "60 배치 학습 후 손실값은  3.8410006567939794\n",
      "70 배치 학습 후 손실값은  8.50500471291163\n",
      "80 배치 학습 후 손실값은  5.623685280918761\n",
      "90 배치 학습 후 손실값은  2.4042199502393347\n",
      "100 배치 학습 후 손실값은  2.986821741753142\n",
      "100 배치 학습 후 검증 데이터에 대한 정확도:  87.91%\n",
      "110 배치 학습 후 손실값은  8.836981848855352\n",
      "120 배치 학습 후 손실값은  3.639570441221318\n",
      "130 배치 학습 후 손실값은  6.216984495854262\n",
      "140 배치 학습 후 손실값은  3.7973158385797134\n",
      "150 배치 학습 후 손실값은  7.859387262749923\n",
      "160 배치 학습 후 손실값은  3.5849229528887534\n",
      "170 배치 학습 후 손실값은  4.091073797828593\n",
      "180 배치 학습 후 손실값은  4.592753150922942\n",
      "190 배치 학습 후 손실값은  7.3917443078928375\n",
      "200 배치 학습 후 손실값은  4.835527177705351\n",
      "200 배치 학습 후 검증 데이터에 대한 정확도:  85.92%\n",
      "210 배치 학습 후 손실값은  5.003539224241831\n",
      "220 배치 학습 후 손실값은  5.52621391983965\n",
      "230 배치 학습 후 손실값은  3.9249624168828134\n",
      "240 배치 학습 후 손실값은  2.0723265950087377\n",
      "250 배치 학습 후 손실값은  4.835428708513507\n",
      "260 배치 학습 후 손실값은  6.5771773683315\n",
      "270 배치 학습 후 손실값은  5.53461201132548\n",
      "280 배치 학습 후 손실값은  6.100970684099781\n",
      "290 배치 학습 후 손실값은  3.453877705585867\n",
      "300 배치 학습 후 손실값은  3.838479313712589\n",
      "300 배치 학습 후 검증 데이터에 대한 정확도:  90.68%\n",
      "310 배치 학습 후 손실값은  2.763105699895901\n",
      "320 배치 학습 후 손실값은  3.7813570045772624\n",
      "330 배치 학습 후 손실값은  4.395803075897879\n",
      "340 배치 학습 후 손실값은  2.0723265950087373\n",
      "350 배치 학습 후 손실값은  3.1184632656316422\n",
      "360 배치 학습 후 손실값은  5.575590235294251\n",
      "370 배치 학습 후 손실값은  5.661327381055439\n",
      "380 배치 학습 후 손실값은  4.260239189527709\n",
      "390 배치 학습 후 손실값은  2.0723265950087377\n",
      "400 배치 학습 후 손실값은  6.368175485763268\n",
      "400 배치 학습 후 검증 데이터에 대한 정확도:  87.24%\n",
      "410 배치 학습 후 손실값은  2.763102124047672\n",
      "420 배치 학습 후 손실값은  6.054183019072158\n",
      "430 배치 학습 후 손실값은  3.8820168723972093\n",
      "440 배치 학습 후 손실값은  3.7694773678538107\n",
      "450 배치 학습 후 손실값은  7.186015051862976\n",
      "460 배치 학습 후 손실값은  3.2902881849718666\n",
      "470 배치 학습 후 손실값은  3.502405139561958\n",
      "480 배치 학습 후 손실값은  4.0477923690924955\n",
      "490 배치 학습 후 손실값은  3.854317554073165\n",
      "500 배치 학습 후 손실값은  3.3734772750700293\n",
      "500 배치 학습 후 검증 데이터에 대한 정확도:  89.61%\n",
      "510 배치 학습 후 손실값은  3.6778606085373844\n",
      "520 배치 학습 후 손실값은  2.7636522742547913\n",
      "530 배치 학습 후 손실값은  3.457903522669501\n",
      "540 배치 학습 후 손실값은  4.688627429663421\n",
      "550 배치 학습 후 손실값은  2.116652217243114\n",
      "560 배치 학습 후 손실값은  2.7632224965466055\n",
      "570 배치 학습 후 손실값은  2.6692040627796256\n",
      "580 배치 학습 후 손실값은  2.0798245593514073\n",
      "590 배치 학습 후 손실값은  2.8128498174216303\n",
      "600 배치 학습 후 손실값은  3.1206399129586186\n",
      "600 배치 학습 후 검증 데이터에 대한 정확도:  89.30%\n",
      "610 배치 학습 후 손실값은  4.144722691349124\n",
      "620 배치 학습 후 손실값은  3.4538776519496945\n",
      "630 배치 학습 후 손실값은  4.835662283485267\n",
      "640 배치 학습 후 손실값은  5.526204236689967\n",
      "650 배치 학습 후 손실값은  2.0723265950087373\n",
      "660 배치 학습 후 손실값은  3.6902534660335484\n",
      "670 배치 학습 후 손실값은  3.4555386053834316\n",
      "680 배치 학습 후 손실값은  2.9274652399113004\n",
      "690 배치 학습 후 손실값은  2.7768921791765524\n",
      "700 배치 학습 후 손실값은  1.9870620110944928\n",
      "700 배치 학습 후 검증 데이터에 대한 정확도:  86.72%\n",
      "710 배치 학습 후 손실값은  2.245482486732773\n",
      "720 배치 학습 후 손실값은  1.63232544676204\n",
      "730 배치 학습 후 손실값은  7.5165766758652826\n",
      "740 배치 학습 후 손실값은  2.0723265950087377\n",
      "750 배치 학습 후 손실값은  2.5376528976671042\n",
      "760 배치 학습 후 손실값은  2.0723265950087377\n",
      "770 배치 학습 후 손실값은  2.936176022396334\n",
      "780 배치 학습 후 손실값은  3.272363861561888\n",
      "790 배치 학습 후 손실값은  2.913044823291897\n",
      "800 배치 학습 후 손실값은  1.3816981014265424\n",
      "800 배치 학습 후 검증 데이터에 대한 정확도:  90.93%\n",
      "810 배치 학습 후 손실값은  4.13255965229985\n",
      "820 배치 학습 후 손실값은  2.2095516974192333\n",
      "830 배치 학습 후 손실값은  1.0680062201492988\n",
      "840 배치 학습 후 손실값은  2.849157958135771\n",
      "850 배치 학습 후 손실값은  3.972021904402673\n",
      "860 배치 학습 후 손실값은  1.3816186217286641\n",
      "870 배치 학습 후 손실값은  2.9900795384400882\n",
      "880 배치 학습 후 손실값은  3.72722194847172\n",
      "890 배치 학습 후 손실값은  2.5987173097957608\n",
      "900 배치 학습 후 손실값은  4.83542872463222\n",
      "900 배치 학습 후 검증 데이터에 대한 정확도:  89.16%\n",
      "910 배치 학습 후 손실값은  4.14526935585066\n",
      "920 배치 학습 후 손실값은  2.3059520917781375\n",
      "930 배치 학습 후 손실값은  3.0271344728396476\n",
      "940 배치 학습 후 손실값은  2.800264941077509\n",
      "950 배치 학습 후 손실값은  1.5208543689873457\n",
      "960 배치 학습 후 손실값은  2.6785873260875888\n",
      "970 배치 학습 후 손실값은  2.7151782421937574\n",
      "980 배치 학습 후 손실값은  5.000109050423157\n",
      "990 배치 학습 후 손실값은  6.915870663279704\n",
      "1에폭에서 검증 데이터에 대한 손실값: 3.250\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Conv2D(out_channels=16,\n",
    "                   param_size=5,\n",
    "                   dropout=0.8,\n",
    "                   weight_init=\"glorot\",\n",
    "                   flatten=True,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190402)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr = 0.1, momentum=0.9))\n",
    "trainer.fit(X_train_conv, train_labels, X_test_conv, test_labels,\n",
    "            epochs = 1,\n",
    "            eval_every = 1,\n",
    "            seed=20190402,\n",
    "            batch_size=60,\n",
    "            conv_testing=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터에 대한 모델의 정확도 : \n",
      "    91.28%\n"
     ]
    }
   ],
   "source": [
    "calc_accuracy_model(model, X_test_conv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
